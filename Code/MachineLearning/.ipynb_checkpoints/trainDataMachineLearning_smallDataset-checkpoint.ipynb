{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library that will convert data taken from pickle to numpy array\n",
    "import pickle # library to import processed data from pickles\n",
    "\n",
    "# create Numpy arrays to hold features and labels\n",
    "# use pickle.load() method to import data from pickle while also using the parametere 'rb' which is for read binary\n",
    "# convert data from pickle to Numpy array using the np.asarray() method\n",
    "image_features = np.asarray(pickle.load(open(\"x_small.pickle\", \"rb\")))\n",
    "labels = np.asarray(pickle.load(open(\"y_small.pickle\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import different modules from machine-learning library -> sklearn \n",
    "from sklearn.preprocessing import MinMaxScaler # used to apply feature scaling to data\n",
    "from sklearn.model_selection import train_test_split # method used to split data into training and test data\n",
    "from sklearn.model_selection import cross_val_score # used to compute the score from training and testing data\n",
    "from sklearn.model_selection import KFold #used to run a k-fold run of the algorithms during training and testing\n",
    "\n",
    "# following objects are improted as Machine Learning Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC # from the SVM algorihtm, use the SVC implementation\n",
    "\n",
    "# python library to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.303732 (0.025940)\n",
      "LDA: 0.300049 (0.024929)\n",
      "KNN: 0.322462 (0.029459)\n",
      "DT: 0.268719 (0.036310)\n",
      "RF: 0.364449 (0.021542)\n",
      "NB: 0.233253 (0.021786)\n",
      "SVC: 0.292202 (0.015929)\n"
     ]
    }
   ],
   "source": [
    "seed = 9 # set random seed for selecting the test data\n",
    "test_size = 0.05 # set  portion of the whole data that will be used for testing\n",
    "scoring = \"accuracy\" # type of perfomance measure of algorithm\n",
    "num_trees = 100 # set number of trees in the Decision Tree Algorithm\n",
    "\n",
    "# create the scaler object from the MinMaxScaler object to match range 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "# scale the image features using the scaler object\n",
    "rescaled_features = scaler.fit_transform(image_features)\n",
    "\n",
    "# again, the rescaled data are converted to a Numpy Array format\n",
    "image_features = np.array(rescaled_features)\n",
    "\n",
    "# method to split data into train and test batch, each batch has features and labels accordingly\n",
    "# include parameteres:\n",
    "# 1. image features\n",
    "# 2. labels\n",
    "# 3. test_size, indicates how much(percentage) of the whole data is allocated for testing\n",
    "# 4. random_state = seed, when selecting the data for testing, because it is a random process, set a random seed\n",
    "(train_image_features, test_image_features, train_labels, test_labels) = train_test_split(np.array(image_features),\n",
    "                                                                                          np.array(labels),\n",
    "                                                                                          test_size = test_size,\n",
    "                                                                                          random_state = seed)\n",
    "# list that will include the name and the Machine Learning Algorithm Object\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state = seed)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators = num_trees, random_state = seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC(random_state = seed)))\n",
    "\n",
    "# for loop to go through all of the machine learning models\n",
    "for name, model in models:\n",
    "    # for each algorithm, do a kfold training process with selected split of data\n",
    "    kfold = KFold(n_splits = 10, random_state = seed)\n",
    "    # corss_val_score returns a list of accuracy results after each testing on data using kfold\n",
    "    cv_results = cross_val_score(model, train_image_features, train_labels, cv = kfold, scoring = scoring)\n",
    "    # compose message to be printed displaying each algorithm's accuracy and standard deviation\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
