{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries that will be used for the pre-processing module\n",
    "import numpy as np #library that will be used to modify the arrays created\n",
    "import random #library to shuffle the array with the data\n",
    "import mahotas\n",
    "import pickle #library that will be used to store the data created into binary files that will be used from the training module\n",
    "import cv2 #library to convert images into numerical (binary files) data (arrays) that can be understood by the training module\n",
    "import os #library that will be used to read folder names, paths\n",
    "\n",
    "# https://gogul.dev/software/image-classification-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direcory where data is stored \n",
    "DATADIR = \"/Users/TarekNagati/Desktop/Final_Year/FYP/Project_to_GetHub/Dataset/smallStructuredData/\"\n",
    "\n",
    "# list of categories that also correspond to the folders\n",
    "CATEGORIES = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "# set the image size for the images to be resized\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# array that will be used to store the data from the images and their labels\n",
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hu Moments from the image by: \n",
    "def getHuMoments(img): # shape                          \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert coloured image to GREYSCALE\n",
    "    moments = cv2.HuMoments(cv2.moments(img)).flatten() # calculate moments(shape) of image using moments and flatten the list\n",
    "    return moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Haralick from image by:\n",
    "def getHaralick(img): # texturet\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert colored image to GREYSCALE\n",
    "    # calculate haralick(texture) and use the mean value of the list\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Histogram from image by:\n",
    "def getHistogram(img, mask=None): # colour\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # convert image to HSV color scale\n",
    "    # calculate the histogram of the image\n",
    "    # The arguments it expects are the image, channels, mask, histSize (bins) \n",
    "    # and ranges for each channel [typically 0-256). \n",
    "    hist  = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    cv2.normalize(hist, hist) # normalize the histogram, changes the range of pixel intensity\n",
    "    hist = hist.flatten() # flatten the histogram array\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to fill the array (training_data) with the images(that are converted into numerical data) and their labels.\n",
    "# for each folder in the folder (structuredData) that represents a category (level of diabetic-retinopahty),\n",
    "# go through each image and:\n",
    "# 1. convert it to numerical data \n",
    "# 2. resize them to IMAGE_SIZE\n",
    "# 3. add the data to the list along with the label (that is the folder name)\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        image_label = int(category) # casting string into int\n",
    "        for img in os.listdir(path): # for each image in the folder\n",
    "                # image processing 2 steps:\n",
    "                # 1)image converted into numerical data\n",
    "                image = cv2.imread(os.path.join(path, img))\n",
    "                # 2)the converted image is resized \n",
    "                #resize the image in order to increase focus and let the machine learning model\n",
    "                #see diferences between images more clearly\n",
    "                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE)) \n",
    "                \n",
    "                moments = getHuMoments(image)#get hu moments from the image \n",
    "                haralick   = getHaralick(image)#get haralick from image\n",
    "                histogram  = getHistogram(image)#get histogram from the image\n",
    "                \n",
    "                #an image feature consists of those three image properties\n",
    "                image_feature = np.hstack([moments, haralick, histogram])\n",
    "                #add the image feature and image label in the data list\n",
    "                training_data.append([image_feature,image_label])\n",
    "            \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data in order not to make connections from order of data\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [] #image\n",
    "y = [] #label of the image\n",
    "\n",
    "#split training data list into two lists, x and y\n",
    "for image_features, image_labels in training_data:\n",
    "    x.append(image_features)\n",
    "    y.append(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the pre-processing is finished, the data is saved as seperate binary files (pickles)\n",
    "# each represent the features (x) and labels(y) of the dataset\n",
    "pickle_out = open(\"x_small.pickle\", \"wb\") # wb = write binary, create the file or open and overwrite if already exists\n",
    "pickle.dump(x, pickle_out) # save all data into the pickle\n",
    "pickle_out.close() # close the pickle\n",
    "\n",
    "pickle_out = open(\"y_small.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
